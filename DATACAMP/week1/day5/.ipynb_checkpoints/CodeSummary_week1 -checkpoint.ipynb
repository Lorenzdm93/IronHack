{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv('file1python.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,file1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    cols.append(data.columns[i].lower())\n",
    "    \n",
    "data.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['tcode', 'domain', 'dob'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={ 'controln':'id','hv1':'median_home_val', 'ic1':'median_household_income'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['id', 'state', 'gender', 'median_home_val', 'median_household_income', 'ic2', 'ic3', 'ic4', 'ic5', 'avggift', 'target_d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['gender'].isin(['M', 'F'])]\n",
    "\n",
    "data[(data['gender']=='M') | (data['gender']=='F')]\n",
    "\n",
    "data[(data['gender']=='M') & (data['state']=='FL')]\n",
    "\n",
    "data[data['target_d']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = data[data['gender']=='M']\n",
    "filtered.head()\n",
    "\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[['gender', 'ic2', 'ic3']][0:10]\n",
    "\n",
    "filtered.loc[1:3]\n",
    "\n",
    "filtered.iloc[1:3] # now i am working just on the indexes row,columns\n",
    "\n",
    "filtered.iloc[1:10,0:4]\n",
    "\n",
    "filtered.iloc[[1,2,3,4],[0,2,4]] #locate by index, first argument row, second columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['median_home_val'] =  pd.to_numeric(data['median_home_val'], errors='coerce')\n",
    "data['median_household_income'] =  pd.to_numeric(data['median_household_income'], errors='coerce')\n",
    "data['ic5'] =  pd.to_numeric(data['ic5'], errors='coerce')\n",
    "data.dtypes\n",
    "# It replaces the values that are not floats to NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data.drop_duplicates()\n",
    "print(data.shape)\n",
    "\n",
    "temp = temp.drop_duplicates(subset=['state','gender', 'ic2', 'ic3'])\n",
    "# if we want to remove duplicates based on some specific columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropping columns with more null values\n",
    "Replacing / imputing null values\n",
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data.isna().sum()/len(data),4)*100  # shows the percentage of null values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe to visualize the above better\n",
    "nulls_df = pd.DataFrame(round(data.isna().sum()/len(data),4)*100)\n",
    "nulls_df = nulls_df.reset_index()\n",
    "nulls_df.columns = ['header_name', 'percent_nulls']\n",
    "nulls_df\n",
    "\n",
    "#now dropping columns with percent null > 3\n",
    "columns_drop = nulls_df[nulls_df['percent_nulls']>3]['header_name']  # dummy case with 3 \n",
    "print(columns_drop.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing / imputing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns: Some ways to approach the problem\n",
    "\n",
    "# Ignore these observations\n",
    "# Replace with general average\n",
    "# Replace with similar type of averages\n",
    "# Build model to predict missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['gender'].isna()==True] # checking rows that are null based on a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ic2'].isna()==False] # Since these nulls are not a lot, we can filter them \n",
    "data = data[data['ic4'].isna()==False]\n",
    "data = data[data['ic5'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_median_home_value = np.mean(data['median_home_val'])\n",
    "data['median_home_val'] = data['median_home_val'].fillna(mean_median_home_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values for categorical variables \n",
    "\n",
    "# General Approaches:\n",
    "    \n",
    "# Ignore observation\n",
    "# Replace by most frequent value\n",
    "# Replace using an algorithm like KNN using the neighbours.\n",
    "# Predict the observation using a multiclass predictor.\n",
    "# Treat missing data as just another category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['gender'].isna()==True])  # number of missing values\n",
    "\n",
    "data['gender'] = data['gender'].fillna('F') #replacing them with F, most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers \n",
    "\n",
    "# This is done using a box plot which we will cover later \n",
    "# After identifying the upper limit and the lower limit values for a numerical column\n",
    "# we can use filters to remove those rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = list(map(lambda x: x.lower(), data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].unique() # check the unique values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = list(map(lambda x: x.upper(), data['gender'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column gender using map function and another user defined function\n",
    "def clean(x):\n",
    "    if x in ['M', 'MALE']:\n",
    "        return 'Male'\n",
    "    elif x.startswith('F'):\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'U'\n",
    "    \n",
    "data['gender'] = list(map(clean, data['gender'])) \n",
    "data['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating buckets / groups of data \n",
    "ic2_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "data['ic2_'] = pd.cut(data['ic2'],4, labels=ic2_labels)\n",
    "# there is also pd.qcut which is based on quantiles. We will discuss it later\n",
    "\n",
    "# pd.cut(data['ic2'],4) # to check the bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Working with datetime format\n",
    "Standardizing input \n",
    "Using string functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['date_time'] = pd.to_datetime(file['date_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['date_time'][0].day\n",
    "file['date_time'][0].month\n",
    "file['date_time'][0].year\n",
    "file['date_time'][0].isoweekday()  # Returns 1 for Monday and so on\n",
    "\n",
    "file['date_time'][0].time()\n",
    "\n",
    "file['date_time'][0].isoweekday()\n",
    "\n",
    "file['date_time'][0].isoformat()\n",
    "\n",
    "file['date_time'][0].strftime(format='%d-%M-%Y')\n",
    "\n",
    "file['date_time'][0].strftime(format=\"%A %d. %B %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.time() # time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.localtime(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.gmtime(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String functions\n",
    "string = \" I am learning  data  analysis at Ironhack  . It is  super easy \"\n",
    "string.lower()\n",
    "string.upper()\n",
    "\n",
    "'34'.isdigit() # does not work with decimal numbers\n",
    "\n",
    "string.lstrip()\n",
    "string.rstrip()\n",
    "string.split()\n",
    "string.split('.')\n",
    "\n",
    "string.replace('  ', ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
